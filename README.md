# CodeDeck

A slide deck for code. Define frames, step through them, export as video.

CodeDeck turns an array of editor states into a presentation you can step through with arrow keys. Each frame describes what the file tree looks like, which file is open, what the code says, where to scroll, and what to highlight — plus optional narration for TTS audio. That's it.

No timeline editors. No drag and drop. No render times. Just declare your states and present.

## Quick start

```
.
├── scripts/                # video scripts (author your .md files here)
│   └── my-video.md
├── videos/                 # rendered output (gitignored)
│   └── my-video.mp4
├── bg-music/               # background music tracks (gitignored)
│   └── some-track.mp3
├── index.html              # the viewer
├── frames.json             # generated intermediate data
├── frames.js               # generated presentation data (loaded by index.html)
├── parse-frames.js         # Node.js parser: *.md → frames.json
├── generate_voices.py      # TTS audio generator (pocket-tts)
├── build-images.sh         # export frames as PNG screenshots (Firefox headless)
├── make_video.sh           # stitch PNGs + audio into MP4 (FFmpeg)
└── build.sh                # run the full pipeline
```

Open `index.html` in a browser. Use **Left** / **Right** arrow keys to step through frames. Append `?frame=N` to the URL to jump to a specific slide.

## Authoring frames

Create a `.md` file in `scripts/` for each video. Frames are separated by `---`. Each frame has metadata lines followed by a fenced code block:

~~~
text: Narration text read aloud during this frame.
selectedFile: src/index.js
scrollLine: 5
highlights: [3, 4, 5]

```javascript
console.log('hello world');
```
~~~

The `text` and `selectedFile` fields are required. The parser builds the file tree automatically from all `selectedFile` paths seen across all frames.

## Build pipeline

Pass your `.md` file to `build.sh`. The output video takes the same name:

```sh
bash build.sh scripts/my-video.md   # → videos/my-video.mp4
```

All your `.md` scripts live in `scripts/` and can be built independently.

Or run steps individually:

| Step | Command | Output |
|------|---------|--------|
| Parse frames | `node parse-frames.js scripts/my-video.md > frames.json` | `frames.json` |
| Generate JS | `bash generate_frames_js.sh` | `frames.js` |
| View in browser | open `index.html` | — |
| Export images | `bash build-images.sh` | `images/frame-NNN.png` |
| Generate audio | `uv run python generate_voices.py` | `audio/frame-NNN.wav` |
| Create video | `bash make_video.sh` | `videos/my-video.mp4` |

## Frame schema

| Field | Type | Description |
|-------|------|-------------|
| `text` | `string` | Narration text used for TTS audio generation. |
| `selectedFile` | `string` | Path of the currently open file. |
| `tree` | `{ path, type }[]` | File tree entries. Auto-generated by the parser. |
| `language` | `string` | Language identifier for highlight.js (e.g. `"javascript"`, `"json"`). |
| `content` | `string` | Plain text content of the open file. |
| `scrollLine` | `number` | 1-indexed line to scroll into view. `0` resets scroll to top. |
| `highlights` | `number[]` | 1-indexed line numbers to highlight. |

## Exporting frames as images

`build-images.sh` uses Firefox in headless mode to capture each frame as a 1920×1080 PNG and saves them to `images/`.

```sh
bash build-images.sh
```

> **Note:** Firefox must be fully closed before running this script. If a Firefox instance is already open, headless mode will try to reuse the existing session and screenshots will not be taken.

## Generating narration audio

`generate_voices.py` reads the `text` field from each frame in `frames.json` and generates a WAV file per frame using the [pocket-tts](https://github.com/marytts/pocket-tts) library.

**Dependencies** (managed via `pyproject.toml`):

```sh
uv sync
```

**Usage:**

```sh
uv run python generate_voices.py
```

Output WAV files are saved to `audio/frame-NNN.wav`.

## Stitching frames into a video

`make_video.sh` stitches the exported PNGs and per-frame audio into a video with crossfade transitions using FFmpeg.

**Dependency:**

```sh
sudo apt install ffmpeg
```

**Usage:**

```sh
bash make_video.sh
```

Output is saved to `videos/` using the filename passed via the `OUTPUT` env var (set automatically by `build.sh`). Each frame's duration is determined by its audio length. Frames without audio fall back to a configurable default duration. Edit the variables at the top of `make_video.sh` to change fade length, resolution, FPS, or output path.

## Background music

Drop any audio file (`.mp3`, `.wav`, `.flac`, `.m4a`) into the `bg-music/` directory and `make_video.sh` will automatically pick it up and mix it into the final video. The first file found (alphabetically) is used, so just keep one track in there at a time:

- Music is low-pass/high-pass filtered and EQ'd to avoid competing with narration
- Sidechain compression ducks the music whenever voice is present
- Narration is lightly compressed for consistency
- Output is loudness-normalised to YouTube's target (-14 LUFS)

To swap tracks, just replace the file in `bg-music/`. If the directory is empty, the music step is silently skipped.

You can download royalty-free tracks from the **YouTube Audio Library** inside YouTube Studio. Ambient / minimal instrumental tracks work best.

## Syntax highlighting

CodeDeck uses [highlight.js](https://highlightjs.org/) loaded from CDN. JavaScript is included by default. To add more languages, add the corresponding `<script>` tag from [cdnjs](https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/languages/):

```html
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/languages/python.min.js"></script>
```

If highlight.js doesn't have the requested language registered, it falls back to plain unstyled text.

## License

MIT
